# Agente Autónomo - Configuración de Ejemplo

# LLM Providers (Completa solo los que vayas a usar)
OPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here
DEEPSEEK_API_KEY=your_deepseek_key_here

# Ollama (Local)
OLLAMA_BASE_URL=http://localhost:11434

# Vision (Túnel HTTPS para acceso móvil)
VISION_TUNNEL_URL=https://your-custom-name.loca.lt

# Configuración del Agente
AUTONOMY_LEVEL=semi  # full, semi, supervised
DEFAULT_MODEL=llama3.2:latest
LLM_PROVIDER=ollama

# Logging
LOG_LEVEL=INFO
